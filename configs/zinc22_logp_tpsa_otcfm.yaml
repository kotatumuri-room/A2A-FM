defaults:
  - default
  - override lr_scheduler: exponentialLR
  - override data_config: zinc22_coati_2dim
  - override data_handler: FM
  - override dataset:  zinc22_coati_logp_tpsa
  - override val_dataset: zinc22_logp_tpsa
  - override model: coati_wrapper
  - override process_generator: FM
  - override optimizer: AdamW
  - override evaluator: zinc22_logp_tpsa
  - _self_

dataset:
  upto: -1
modelname: zinc22_logp_tpsa_FM


train_dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 1 #一つあたり1024個
  shuffle: true
  num_workers: 10
  drop_last: true
val_dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 1 #一つあたり1024個 
  shuffle: false
  num_workers: 0
  drop_last: true
trainer:
  devices: 1
  precision: 32
  check_val_every_n_epoch: 100
  strategy: ddp_find_unused_parameters_true
  max_epochs: 100