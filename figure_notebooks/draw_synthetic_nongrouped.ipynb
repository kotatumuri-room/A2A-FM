{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from script.datasets.synthetic import CircleMixturedFilledGaussianDataset\n",
    "from script.process_based_generative_model import ProcessBasedGenerativeModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your trained .ckpt file paths here\n",
    "A2AFM_PATH = \n",
    "DIFFUSION_CFG_PATH = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(A2AFM_PATH)\n",
    "path = list(path.glob(\"*.ckpt\"))[0]\n",
    "print(path)\n",
    "model = ProcessBasedGenerativeModel.load_from_checkpoint(path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CircleMixturedFilledGaussianDataset(\n",
    "    10000, data_config=model.config.data_config\n",
    ")\n",
    "plt.scatter(dataset.xdata[:, 0], dataset.xdata[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "target_theta = torch.pi/2\n",
    "initial_theta = torch.pi/4\n",
    "initc = torch.ones(100, 1, device=\"cuda\") * initial_theta\n",
    "xdata = dataset.sample(initial_theta, 100)\n",
    "targc = torch.ones(100, 1, device=\"cuda\") * target_theta\n",
    "ydata = dataset.sample(target_theta, 100)\n",
    "\n",
    "x0 = xdata\n",
    "x1 = ydata\n",
    "M = ot.dist(x0, x1)\n",
    "pi = ot.emd(torch.ones(len(x0)) / len(x0), torch.ones(len(x1)) / len(x1), M)\n",
    "idx = torch.argmax(pi, dim=1)\n",
    "traj = torch.stack(\n",
    "    ([(1 - t) * x0 + t * x1[idx] for t in torch.linspace(0, 1, 100)]), dim=0\n",
    ")\n",
    "plt.grid()\n",
    "plt.scatter(dataset.xdata[:, 0], dataset.xdata[:, 1],alpha=0.1,s=1,c=\"gray\")\n",
    "plt.scatter(traj[:, :, 0], traj[:, :, 1], alpha=1, s=0.1, c=\"tan\")\n",
    "plt.scatter(ydata[:, 0], ydata[:, 1], label=\"target points\")\n",
    "plt.scatter(xdata[:, 0], xdata[:, 1], label=\"initial points\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xticks([0.0,0.5,1.0,1.5,2.0])\n",
    "plt.yticks([0.0,0.5,1.0,1.5,2.0])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate A2A-FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = model.evaluator.integrate(xdata.cuda().clone(), targc.clone(), initc=initc.clone()).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset.xdata[:, 0], dataset.xdata[:, 1],alpha=0.1,s=1,c=\"gray\")\n",
    "plt.scatter(ydata[:, 0], ydata[:, 1], label=\"target points\")\n",
    "plt.scatter(traj[:, :, 0], traj[:, :, 1], alpha=1, s=0.1, c=\"tan\")\n",
    "plt.scatter(xdata[:, 0], xdata[:, 1], label=\"initial points\")\n",
    "plt.scatter(traj[-1, :, 0], traj[-1, :, 1], alpha=1, label=\"generated points\")\n",
    "plt.legend()\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate partial diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(DIFFUSION_CFG_PATH)\n",
    "path = list(path.glob(\"*.ckpt\"))[0]\n",
    "model = ProcessBasedGenerativeModel.load_from_checkpoint(path)\n",
    "model.eval()\n",
    "traj = model.evaluator.partial_diffusion(xdata.cuda(), targc,timesteps=0.3).cpu()\n",
    "traj = torch.stack(\n",
    "    [traj[-1] * t + xdata * (1 - t) for t in torch.linspace(0, 1, 100)], dim=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset.xdata[:, 0], dataset.xdata[:, 1],alpha=0.1,s=1,c=\"gray\")\n",
    "plt.scatter(ydata[:, 0], ydata[:, 1], label=\"target points\")\n",
    "plt.scatter(traj[:, :, 0], traj[:, :, 1], alpha=1, s=0.1, c=\"tan\")\n",
    "plt.scatter(xdata[:, 0], xdata[:, 1], label=\"initial points\")\n",
    "plt.scatter(traj[-1, :, 0], traj[-1, :, 1], alpha=1, label=\"generated points\")\n",
    "plt.legend()\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Multimariginal SI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "\n",
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from stochastic_interpolant.path_optimizer import PathOptimizer\n",
    "from stochastic_interpolant.utils import Velocity\n",
    "from stochastic_interpolant.vector_field import VelocityField\n",
    "\n",
    "\n",
    "def get_filename(logdir):\n",
    "    versions = sorted(list(logdir.glob(\"version_*\")))\n",
    "    if len(versions) == 0:\n",
    "        versions.append(logdir / \"version_0\")\n",
    "    latest_number = int(versions[-1].name[8:])\n",
    "    return logdir / f\"version_{latest_number+1}\"\n",
    "\n",
    "\n",
    "with hydra.initialize(\n",
    "    version_base=None, config_path=\"../stochastic_interpolants_config\"\n",
    "):\n",
    "    config = hydra.compose(config_name=\"synthetic\")\n",
    "val_datasets = instantiate(config.val_datasets, _recursive_=False)\n",
    "K = len(val_datasets)\n",
    "root_dir = Path(config.savedir)\n",
    "ckpt_dirs_vf = [root_dir / f\"g{k}\" for k in range(K)]\n",
    "c_list = config.c_list\n",
    "assert len(c_list) == K\n",
    "gs = []\n",
    "gt_versions = [-1] * len(ckpt_dirs_vf)\n",
    "if hasattr(config, \"ckpt_versions_gt\"):\n",
    "    gt_versions = config.ckpt_versions_gt\n",
    "    print(gt_versions)\n",
    "\n",
    "for ckpt_dir, v in zip(ckpt_dirs_vf, gt_versions):\n",
    "    ckpt_path = ckpt_dir / \"lightning_logs\" / f\"version_{v}\" / \"checkpoints\"\n",
    "    ckpt_path = list(ckpt_path.glob(\"*.ckpt\"))[0]\n",
    "    print(f\"using check point {ckpt_path}\")\n",
    "    gs.append(\n",
    "        VelocityField.load_from_checkpoint(ckpt_path, myconfig=config.vector_field)\n",
    "    )\n",
    "logdir = root_dir / \"total_logs\"\n",
    "logdir = get_filename(logdir)\n",
    "\n",
    "\n",
    "def prepare_vel(i, j):\n",
    "    reverse = False\n",
    "    if j < i:\n",
    "        reverse = True\n",
    "        tmp = i\n",
    "        i = j\n",
    "        j = tmp\n",
    "    ckpt_dir = root_dir / f\"alpha_{i}_{j}\"\n",
    "    ckpt_path = sorted(list(ckpt_dir.rglob(\"*.ckpt\")))[-1]\n",
    "    print(f\"using check point {ckpt_path}\")\n",
    "    alpha = PathOptimizer.load_from_checkpoint(\n",
    "        ckpt_path, myconfig=config.alpha, gs=gs, i=i, j=j, datasets=val_datasets\n",
    "    )\n",
    "    vel = Velocity(gs, alpha, reverse=reverse)\n",
    "    return vel\n",
    "\n",
    "\n",
    "def prepare_vels():\n",
    "    K = config.K\n",
    "    alphas = [[None] * K for _ in range(K)]\n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            if i == j:\n",
    "                continue\n",
    "            alphas[i][j] = prepare_vel(i, j)\n",
    "    return alphas\n",
    "\n",
    "\n",
    "def get_index(c: torch.Tensor):\n",
    "    classes = (\n",
    "        torch.bucketize(c, torch.linspace(0, torch.pi / 2, K + 1, device=c.device)) - 1\n",
    "    )\n",
    "    classes = torch.clip(classes, min=0)\n",
    "    return classes\n",
    "\n",
    "\n",
    "vels = prepare_vels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def integrate(initx, initc, targc):\n",
    "    b, d = initx.shape\n",
    "    ts = torch.linspace(0, 1, 100, device=initx.device)\n",
    "    traj = initx.expand(len(ts), b, d).clone()\n",
    "    i = get_index(initc)[0]\n",
    "    js = get_index(targc)\n",
    "    for j in range(10):\n",
    "        x0 = initx[(js == j).squeeze()]\n",
    "        if len(x0) == 0:\n",
    "            continue\n",
    "        if i == j:\n",
    "            continue\n",
    "        print(i, j)\n",
    "        vel = vels[i][j]\n",
    "        traj[:, (js == j).squeeze(), :] = odeint(vel, x0, ts).squeeze(1).clone()\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = integrate(xdata.cuda(), initc, targc).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset.xdata[:, 0], dataset.xdata[:, 1],alpha=0.1,s=1,c=\"gray\")\n",
    "plt.scatter(ydata[:, 0], ydata[:, 1], label=\"target points\")\n",
    "plt.scatter(traj[:, :, 0], traj[:, :, 1], alpha=1, s=0.1, c=\"tan\")\n",
    "plt.scatter(xdata[:, 0], xdata[:, 1], label=\"initial points\")\n",
    "plt.scatter(traj[-1, :, 0], traj[-1, :, 1], alpha=1, label=\"generated points\")\n",
    "plt.legend()\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qunatative Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def eval_model(model,targthetas,initthetas):\n",
    "    error = []\n",
    "    for initial_theta,target_theta in  tqdm(zip(initthetas,targthetas),total=len(targthetas)):\n",
    "        initc = torch.ones(100, 1, device=\"cuda\") * initial_theta\n",
    "        xdata = dataset.sample(initial_theta, 100)\n",
    "        targc = torch.ones(100, 1, device=\"cuda\") * target_theta\n",
    "        ydata = dataset.sample(target_theta, 100)\n",
    "        traj = model.evaluator.integrate(xdata.cuda().clone(), targc.clone(), initc=initc.clone()).cpu()\n",
    "        x0 = xdata\n",
    "        x1 = ydata\n",
    "        M = ot.dist(x0, x1)\n",
    "        pi = ot.emd(torch.ones(len(x0)) / len(x0), torch.ones(len(x1)) / len(x1), M)\n",
    "        idx = torch.argmax(pi, dim=1)\n",
    "        error.append(torch.mean((x1[idx] - traj[-1]) ** 2))\n",
    "    return np.mean(error)\n",
    "def eval_model_partial_diffusion(model,targthetas,initthetas,t=0.5,w=0.3):\n",
    "    error = []\n",
    "    for initial_theta,target_theta in tqdm(zip(initthetas,targthetas),total=len(targthetas)):\n",
    "        initc = torch.ones(100, 1, device=\"cuda\") * initial_theta\n",
    "        xdata = dataset.sample(initial_theta, 100)\n",
    "        targc = torch.ones(100, 1, device=\"cuda\") * target_theta\n",
    "        ydata = dataset.sample(target_theta, 100)\n",
    "        traj = model.evaluator.partial_diffusion(xdata.cuda(), targc,timesteps=t,w=w).cpu()\n",
    "        x0 = xdata\n",
    "        x1 = ydata\n",
    "        M = ot.dist(x0, x1)\n",
    "        pi = ot.emd(torch.ones(len(x0)) / len(x0), torch.ones(len(x1)) / len(x1), M)\n",
    "        idx = torch.argmax(pi, dim=1)\n",
    "        error.append(torch.mean((x1[idx] - traj[-1]) ** 2))\n",
    "    return np.mean(error)\n",
    "        \n",
    "def eval_model_sto_interp(targthetas,initthetas):\n",
    "    error = []\n",
    "    for initial_theta,target_theta in tqdm(zip(initthetas,targthetas),total=len(targthetas)):\n",
    "        initc = torch.ones(100, 1, device=\"cuda\") * initial_theta\n",
    "        xdata = dataset.sample(initial_theta, 100)\n",
    "        targc = torch.ones(100, 1, device=\"cuda\") * target_theta\n",
    "        ydata = dataset.sample(target_theta, 100)\n",
    "        traj  = integrate(xdata.cuda(), initc, targc).cpu()\n",
    "        x0 = xdata\n",
    "        x1 = ydata\n",
    "        M = ot.dist(x0, x1)\n",
    "        pi = ot.emd(torch.ones(len(x0)) / len(x0), torch.ones(len(x1)) / len(x1), M)\n",
    "        idx = torch.argmax(pi, dim=1)\n",
    "        error.append(torch.mean((x1[idx] - traj[-1]) ** 2))\n",
    "        \n",
    "    return np.mean(error)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targthetas=np.random.rand(100)*np.pi/2\n",
    "initthetas=np.random.rand(100)*np.pi/2\n",
    "path = Path(\n",
    "    A2AFM_PATH\n",
    ")\n",
    "path = list(path.glob(\"*.ckpt\"))[0]\n",
    "print(path)\n",
    "model = ProcessBasedGenerativeModel.load_from_checkpoint(path)\n",
    "model.eval()\n",
    "ours_loss = eval_model(model,targthetas,initthetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = Path(\n",
    "    DIFFUSION_CFG_PATH\n",
    ")\n",
    "path = list(path.glob(\"*.ckpt\"))[0]\n",
    "model = ProcessBasedGenerativeModel.load_from_checkpoint(path)\n",
    "model.eval()\n",
    "partial_diffuson_loss = eval_model_partial_diffusion(model,targthetas,initthetas,w=0.3,t=0.3)\n",
    "path = Path(\n",
    "   DIFFUSION_CFG_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sto_interp_loss = eval_model_sto_interp(targthetas,initthetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE from pairwise OT (A2A-FM): \", ours_loss)\n",
    "print(\"MSE from pairwise OT (Partial Diffusion): \", partial_diffuson_loss)\n",
    "print(\"MSE from pairwise OT (Stochastic Interpolant): \", sto_interp_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
